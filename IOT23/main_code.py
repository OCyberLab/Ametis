# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"""Data Augmentation EXP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GZE5jzH1eGa_dGPunVNfJ2y01X38R3F8

#Import Packages
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import gc
import pandas as pd
import numpy as np
import os
from sklearn.utils import shuffle
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import make_scorer
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten

"""#Functions"""

def clean_data_cic(df):
    # Missing Values
    df = df.replace('-', float('NaN'))
    df.fillna(0, inplace=True)

    for col in df.columns:
        if df[col].dtype == 'float64' and df[col].mean() == 0:
            df[col] = df[col].astype(pd.SparseDtype(float, fill_value=0))

    # Dealing with Duplicate Data
    df = df.drop_duplicates()

    return df

def scale_data_cic(df_train, test_path):
  scaler = MinMaxScaler(feature_range=(0, 1))

  y_train = np.where(df_train.label.str.contains('Benign'), 0, 1)
  x = df_train.drop(['label'], axis=1)
  
  # One-hot encoding for categorical data
  categorical_cols = x.select_dtypes(include=['object', 'category']).columns
  df = pd.get_dummies(x, columns=categorical_cols, drop_first=True)

  df_test = pd.read_csv(test_path)
  df_test = clean_data_cic(df_test)
  
  x_test = df_test.reindex(labels=x.columns,axis=1)
  x_test.replace(float('NaN'), 0, inplace=True)
  y_test = np.where(df_test.label.str.contains('Benign'), 0, 1)
  
  X_train_scaled = scaler.fit_transform(x)  # compute min, max of the training data and scale it
  X_test_scaled = scaler.transform(x_test)  # scale test data using the same min and max values

  return X_train_scaled, y_train, X_test_scaled, y_test

def clean_data(df):
  # Missing Values
  df = df.replace('-', float('NaN'))

  nan_columns = ['local_resp', 'local_orig']
  if 'id.orig_h' in df.columns:
        df.rename(columns={'id.orig_h': 'id_orig_h'}, inplace=True)
  if 'id.resp_h' in df.columns:
        df.rename(columns={'id.resp_h': 'id_resp_h'}, inplace=True)
  features_for_removal = ['id_orig_h', 'id_resp_h']
  df.drop(features_for_removal, axis=1, inplace=True)
  df["service"].fillna("No Service", inplace = True)
  df["conn_state"].fillna("No State", inplace = True)

#  df.drop(nan_columns, axis=1, inplace=True)
#  df.dropna(inplace=True)
  df.fillna(0, inplace = True)

  for col in df.columns:
    if df[col].dtype == 'float64' and df[col].mean() == 0:
        df[col] = df[col].astype(pd.SparseDtype(float, fill_value=0))

  # Dealing with Duplicate Data
  df = df.drop_duplicates()
  # Delete unnessary coloumns
  df.drop(['ts', 'uid'], axis=1, inplace=True)

#  # Reduce dataset size to 50%
#  df = df.sample(frac=0.5, random_state=42)
  df = preprocess_data_with_one_hot(df)
  return df

from sklearn.preprocessing import LabelEncoder

def preprocess_data_with_label_encoder(df):
    if 'label' in df.columns:
        df = df.drop(columns=['label'])
    symbolic_coloumns = df.select_dtypes(include=['object', 'category']).columns
    encoder = LabelEncoder()
    for column in symbolic_coloumns:
        if column != 'label':
            df[column] = df[column].astype(str)
            df[column] = encoder.fit_transform(df[column])
    df.fillna(0, inplace=True)
    return df
    
def preprocess_data_with_one_hot(df, isCIC=False):
    if 'label' in df.columns and isCIC:
        df = df.drop(columns=['label'])
#    symbolic_coloumns = df.select_dtypes(include=['object', 'category']).columns
#    symbolic_coloumns = [col for col in symbolic_coloumns if col != 'label']
#    else:
    symbolic_coloumns = ['history', 'proto', 'service', 'conn_state']
    encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' can be used to avoid dummy variable trap
    encoded_df = pd.DataFrame()

    for column in symbolic_coloumns:
        if column != 'label':
            # Ensure the column is of type str
            df[column] = df[column].astype(str)
            encoded_features = encoder.fit_transform(df[[column]])
            temp_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out([column]))
            # Reset index before concatenating
            encoded_df = pd.concat([encoded_df.reset_index(drop=True), temp_df.reset_index(drop=True)], axis=1)

    # Reset index before concatenating the main df with encoded_df
    df = pd.concat([df.reset_index(drop=True), encoded_df], axis=1)
    df.drop(symbolic_coloumns, axis=1, inplace=True)
    df.fillna(0, inplace=True)
    return df

def scale_data(df_train, test_path):
  scaler = MinMaxScaler(feature_range=(0, 1))

  print(df_train.columns)
  y_train = np.where(df_train['label'].str.contains('Benign'), 0, 1)
  x_train = df_train.drop(['label'], axis=1)

  test_df = pd.read_csv(test_path)
  test_df = clean_data(test_df)
  y_test = test_df['label']
  x_test = test_df.reindex(labels=x_train.columns,axis=1)
  x_test.replace(float('NaN'), 0, inplace=True)
  
  print(x_test.shape)
  print(x_train.shape)

  # y_test = test_df['label']
#  x_test = test_df.drop(['label'], axis=1)

  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

  X_train_scaled = scaler.fit_transform(x_train)  # compute min, max of the training data and scale it
  X_test_scaled = scaler.transform(x_test)  # scale test data using the same min and max values

  return X_train_scaled, y_train, X_test_scaled, y_test

def check_row_exist(csv_path, feature_selection, scenario, model_name, train_dataset_name):
  """
  Check if the row exists in the feature_selection dataframe.

  Args:
    feature_selection: The feature_selection dataframe.
    scenario: The scenario.
    model_name: The model name.
    train_dataset_name: The train dataset name.

  Returns:
    A boolean value indicating whether the row exists or not.
  """

  if os.path.exists(csv_path):
    # Load the existing CSV file
    df = pd.read_csv(csv_path)
  else:
    print("RESULT FILE NOT FOUND FALSE")
    return False

  row = df[
      (df['Scenario'] == scenario) &
      (df['Model'] == model_name) &
      (df["Feature Selection"] == feature_selection) &
      (df["Dataset"] == train_dataset_name)]
  return len(row) > 0

def update_csv(csv_path, column_names, model_name, result, auc_score, total_time, feature_selection, train_dataset_name, selected_features, total_features, feature_selection_total_time, scenario, epochs):
    # Create folder if it doesn't exist
    os.makedirs(os.path.dirname(csv_path), exist_ok=True)  # Create parent directories

    # Check if the CSV file exists
    if os.path.exists(csv_path):
        print_green("Result File exists")
        # Load the existing CSV file
        df = pd.read_csv(csv_path)
    else:
        # Create a new CSV file with specified column names
        df = pd.DataFrame(columns=column_names)
        df.to_csv(csv_path, index=False)

    avg_time_per_trial = total_time / 10
    new_row = pd.DataFrame([[0]*len(df.columns)], columns=df.columns)

    avg_time_per_trial = total_time / 10
    # Load or create the DataFrame

    # Create a new row with zeros
    new_row = pd.DataFrame([[0]*len(column_names)], columns=column_names)

    # Update the new row with the results
    new_row["Accuracy"] = result['accuracy']
    new_row["G-Mean"] = result['gmean']
    new_row["F1-Micro"] = result['f1_micro']
    new_row["F1-Macro"] = result['f1_macro']
    new_row["F1-Score"] = result['weighted avg']['f1-score']
    new_row["Recall"] = result['weighted avg']['recall']
    new_row["Precision"] = result['weighted avg']['precision']
    new_row["AUC"] = auc_score
    new_row["Epochs"] = epochs

    new_row["Model"] = model_name

    # Set other fields (replace 'accuracy' with the actual values you want to set)
    new_row["Model Training Total Time"] = total_time
    new_row["Feature Selection"] = feature_selection
    new_row["Dataset"] = train_dataset_name
    new_row["Scenario"] = scenario
    new_row["Selected Features"] = selected_features
    new_row["Total Features"] = total_features
    new_row["Feature Selection Time"] = feature_selection_total_time

    # Append the new row and save
    df = pd.concat([df, new_row], ignore_index=True)
    df.to_csv(csv_path, index=False)

def train_model_scenario(model_name, scenario, x, x_test, y, y_test, feature_selection, feature_selection_total_time, total_features):
    result, auc_score, selected_features, _, keras_tuner_total_time = train_model(model_name, x, y, x_test, y_test, train_dataset_name, scenario, epochs, feature_selection)
    update_csv(model_name, result, auc_score, keras_tuner_total_time, feature_selection, train_dataset_name, selected_features, total_features, feature_selection_total_time, scenario, epochs)

def remove_folder(folder_path):
    # Check if the folder exists
    if os.path.exists(folder_path):
        # Remove the folder
        shutil.rmtree(folder_path)
        print(f"Folder '{folder_path}' has been removed.")
    else:
        print(f"Folder '{folder_path}' does not exist.")

def cleanup(model, x, y, x_test, y_test, anomalies):
    del(model)
    del(x)
    del(y)
    del(x_test)
    del(y_test)
    del(anomalies)
    gc.collect()

def print_green(text):
    print("\033[92m" + text + "\033[0m")


def get_tuner_times(tuner):
    best_trials = trials = tuner.oracle.trials
    print(tuner.oracle._run_times)

    # Initialize a list to store the duration of each trial
    trial_durations = []

    # Loop through each trial to calculate its duration
    for trial_id, trial in trials.items():
        print(trial)
        start_time = trial.start_time
        end_time = trial.end_time
        duration = end_time - start_time
        trial_durations.append(duration)

    avg_time_per_trial = sum(trial_durations) / len(trial_durations)
    total_time = sum(trial_durations)

    print(f"Model: {model_name}")
    print(f"Average time per trial: {avg_time_per_trial} seconds")
    print(f"Total time for all trials: {total_time} seconds")
    return avg_time_per_trial, total_time

"""# Models"""

from prompt_toolkit.formatted_text.utils import fragment_list_to_text
import tensorflow as tf

from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LeakyReLU
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from imblearn.over_sampling import SMOTE
from keras_tuner import RandomSearch, Objective
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import gc
from keras_tuner.engine.hypermodel import HyperModel
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras import backend as K
import shutil
import random
from sklearn.metrics import balanced_accuracy_score
from tensorflow.keras.regularizers import l1
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, f1_score, accuracy_score


# Utility function to ensure model directory exists
def ensure_model_directory_exists(train_dataset_name):
    model_directory_path = os.path.join("", "models", train_dataset_name)
    if not os.path.exists(model_directory_path):
        os.makedirs(model_directory_path)

# F1 Macro metric
def f1_macro(y_true, y_pred):
    def recall(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        return recall

    def precision(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision

    precision = precision(y_true, y_pred)
    recall = recall(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))



from keras.models import Sequential, Model
from keras.layers import Input, Dense, BatchNormalization, Dropout
from keras.optimizers import Adam
from keras.regularizers import l1, l2

from keras.models import Sequential, Model
from keras.layers import Input, Dense, BatchNormalization, Dropout
from keras.optimizers import Adam
from keras.regularizers import l1, l2

class AutoEncoderHyperModel:
    def __init__(self, input_dim, hp, reg_type=""):
        self.input_dim = input_dim
        self.hp = hp
        self.reg_type = reg_type

    def build(self):
        input_layer = Input(shape=(self.input_dim,))

        # Hyperparameters
        encoder_dim = self.hp.Int('encoder_dim', min_value=32, max_value=512, step=32)
        decoder_dim = self.hp.Int('decoder_dim', min_value=16, max_value=encoder_dim // 2, step=32)
        reg_strength = self.hp.Float('l1_l2_reg', min_value=1e-6, max_value=1e-2, sampling='log')
        optimizer_choice = self.hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])
        loss_choice = self.hp.Choice('loss', ['mae', 'mse', 'huber'])

        # Apply regularization conditionally
        if self.reg_type == 'L1':
            regularizer = l1(reg_strength)
        elif self.reg_type == 'L2':
            regularizer = l2(reg_strength)
        else:
            regularizer = None  # No regularization

        # Build the model layers with the selected hyperparameters
        encoder = Dense(encoder_dim, activation="tanh", activity_regularizer=regularizer)(input_layer)
        encoder = BatchNormalization()(encoder)
        encoder = Dense(encoder_dim // 2, activation="relu")(encoder)
        decoder = Dense(decoder_dim, activation='sigmoid')(encoder)
        decoder = BatchNormalization()(decoder)
        decoder = Dense(self.input_dim, activation='relu')(decoder)

        autoencoder = Model(inputs=input_layer, outputs=decoder)
        autoencoder.compile(optimizer=optimizer_choice, loss=loss_choice)
        return autoencoder


class AutoEncoderModel:
    def __init__(self, input_dim, encoder_dim=512, decoder_dim=16, optimizer_choice='rmsprop', loss_choice='mae', reg_type="", reg_strength=0.0001):
        self.input_dim = input_dim
        self.encoder_dim = encoder_dim
        self.decoder_dim = decoder_dim
        self.optimizer_choice = optimizer_choice
        self.loss_choice = loss_choice
        self.reg_type = reg_type
        self.reg_strength = reg_strength

    def build(self):
        input_layer = Input(shape=(self.input_dim,))

        # Choose the regularizer based on the reg_type
        if self.reg_type == "L1":
            regularizer = l1(self.reg_strength)
        elif self.reg_type == "L2":
            regularizer = l2(self.reg_strength)
        else:
            regularizer = None

        # Build the model layers with the selected regularizer
        encoder = Dense(self.encoder_dim, activation="tanh", activity_regularizer=regularizer)(input_layer)
        encoder = BatchNormalization()(encoder)
        encoder = Dense(self.encoder_dim // 2, activation="relu")(encoder)
        decoder = Dense(self.decoder_dim, activation='sigmoid')(encoder)
        decoder = BatchNormalization()(decoder)
        decoder = Dense(self.input_dim, activation='relu')(decoder)

        autoencoder = Model(inputs=input_layer, outputs=decoder)
        autoencoder.compile(optimizer=self.optimizer_choice, loss=self.loss_choice)
        return autoencoder

from tensorflow.keras.optimizers import Adam, RMSprop, SGD

class HCSHyperModel:
    def __init__(self, input_dim, hp, reg_type=""):
        self.input_dim = input_dim
        self.hp = hp
        self.reg_type = reg_type

    def build(self):
        model = Sequential()

        # Hyperparameters
        units = self.hp.Int('units', min_value=32, max_value=512, step=32)
        dropout_rate = self.hp.Float('dropout_rate', min_value=0.1, max_value=0.7, step=0.1)
        learning_rate = self.hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')
        reg_strength = self.hp.Float('reg_strength', min_value=1e-6, max_value=1e-2, sampling='log')
        optimizer_choice = self.hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])

        # Apply regularization conditionally
        if self.reg_type == 'L1':
            regularizer = l1(reg_strength)
        elif self.reg_type == 'L2':
            regularizer = l2(reg_strength)
        else:
            regularizer = None  # No regularization

        # Build the model layers with the selected hyperparameters
        model.add(Dense(units=units, activation='selu', kernel_initializer='lecun_normal',
                        kernel_regularizer=regularizer, input_dim=self.input_dim))
        model.add(BatchNormalization())
        model.add(Dropout(dropout_rate))
        model.add(Dense(units=units, activation='selu', kernel_initializer='lecun_normal',
                        kernel_regularizer=regularizer))
        model.add(BatchNormalization())
        model.add(Dropout(dropout_rate))
        model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizer))

        # Select optimizer based on choice
        if optimizer_choice == 'adam':
            optimizer = Adam(learning_rate=learning_rate)
        elif optimizer_choice == 'rmsprop':
            optimizer = RMSprop(learning_rate=learning_rate)
        elif optimizer_choice == 'sgd':
            optimizer = SGD(learning_rate=learning_rate)
        else:
            optimizer = Adam(learning_rate=learning_rate)  # Default optimizer

        model.compile(optimizer=optimizer, loss="binary_crossentropy")

        return model


class HCSModel:
    def __init__(self, input_dim, units=128, learning_rate=1e-4, reg_type="", reg_strength=1e-4):
        self.input_dim = input_dim
        self.units = units
        self.learning_rate = learning_rate
        self.reg_type = reg_type
        self.reg_strength = reg_strength

    def build(self):
        model = Sequential()

        # Select the regularizer based on reg_type
        if self.reg_type == "L1":
            regularizer = l1(self.reg_strength)
        elif self.reg_type == "L2":
            regularizer = l2(self.reg_strength)
        else:
            regularizer = None

        # Add layers with or without regularization
        model.add(Dense(units=self.units, activation='selu', kernel_initializer='lecun_normal',
                        kernel_regularizer=regularizer, input_dim=self.input_dim))
        model.add(BatchNormalization())
        model.add(Dropout(0.5))
        model.add(Dense(units=self.units, activation='selu', kernel_initializer='lecun_normal',
                        kernel_regularizer=regularizer))
        model.add(BatchNormalization())
        model.add(Dropout(0.5))
        model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizer))
        opt = Adam(learning_rate=self.learning_rate)
        model.compile(optimizer=opt, loss="binary_crossentropy")

        return model
def build_lstm_model(input_shape, dropout_rate=0.5, lstm_units=50):
    """
    Build a simple LSTM model for binary classification.

    Parameters:
    - input_shape (tuple): Shape of the input data (timesteps, features).
    - dropout_rate (float): Dropout rate for regularization.
    - lstm_units (int): Number of LSTM units.

    Returns:
    - model (tf.keras.Model): Compiled LSTM model.
    """

    model = Sequential()

    # LSTM layer
    model.add(LSTM(units=lstm_units, input_shape=input_shape, return_sequences=True))
    model.add(Dropout(dropout_rate))

    # LSTM layer
    model.add(LSTM(units=lstm_units))
    model.add(Dropout(dropout_rate))

    # Dense output layer for binary classification
    model.add(Dense(1, activation='sigmoid'))

    # Compile the model
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    return model

"""# Run and Apply Model"""

from keras.losses import get

def custom_f1_scorer(y_true, y_pred):
    # Calculate F1-macro and F1-micro scores
    f1_macro = f1_score(y_true, y_pred, average='macro')
    f1_micro = f1_score(y_true, y_pred, average='micro')

    # Compute the average of F1-macro and F1-micro
    average_f1 = (f1_macro + f1_micro) / 2
    return average_f1

def compute_model_predictions(model, model_name, x, y, x_test, y_test):
    if model_name in ["LSTM", "LSTM_HT"]:
        batch_size = 64
        test_loss = np.zeros(len(x_test))  # Initialize an array of zeros for test loss

        # Compute reconstruction error in batches
        for i in range(0, len(x_test), batch_size):
            end_idx = min(i + batch_size, len(x_test))  # Ensure not to exceed the array length
            batch_x_test = x_test[i:end_idx]
            X_test_pred = model.predict(batch_x_test)
            # Ensure both arrays are 2D before subtraction
            batch_x_test_reshaped = batch_x_test.reshape(batch_x_test.shape[0], -1)
            X_test_pred_reshaped = X_test_pred.reshape(X_test_pred.shape[0], -1)
            batch_test_loss = np.mean(np.square(batch_x_test_reshaped - X_test_pred_reshaped), axis=1)
            test_loss[i:end_idx] = batch_test_loss

        # Compute training loss in batches
        training_loss = np.zeros(len(x))
        for i in range(0, len(x), batch_size):
            end_idx = min(i + batch_size, len(x))
            batch_x = x[i:end_idx]
            X_train_pred = model.predict(batch_x)
            # Reshape for consistency
            batch_x_reshaped = batch_x.reshape(batch_x.shape[0], -1)
            X_train_pred_reshaped = X_train_pred.reshape(X_train_pred.shape[0], -1)
            batch_training_loss = np.mean(np.square(batch_x_reshaped - X_train_pred_reshaped), axis=1)
            training_loss[i:end_idx] = batch_training_loss

        # Determine the threshold
        threshold = np.mean(training_loss) + 2 * np.std(training_loss)

        # Detect anomalies
        anomalies = test_loss > threshold
    if model_name in ["IF", "IF_HT"]:
      anomalies = model.predict(x_test)
      # Convert anomalies labels from {-1, 1} to a binary format that matches your evaluation function's expectations
      anomalies = np.where(anomalies == -1, 1, 0)
      return anomalies
    if model_name not in ["XGBoost", "XGBoost_HT", "RF", "RF_HT"]:
        loss_function = get(model.loss)
        X_test_pred = model.predict(x_test)
        test_loss = loss_function(x_test, X_test_pred)
        X_train_pred = model.predict(x)
        training_loss = loss_function(x, X_train_pred)

        lower_limit = np.mean(training_loss)
        upper_limit = np.mean(training_loss) + 2 * np.std(training_loss)
        thresholds = np.linspace(lower_limit, upper_limit, num=100)

        best_f1 = 0
        best_threshold = 0
        for threshold in thresholds:
            anomalies = test_loss > threshold
            f1 = f1_score(y_test, anomalies)
            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold

        anomalies = test_loss > best_threshold
    else:
        anomalies = model.predict(x_test)

    return anomalies

def evaluate_model(anomalies, y_test):
    target_names = ['class 0', 'class 1']
    result = classification_report(y_test, anomalies, output_dict=True, target_names=target_names)

    gmean = balanced_accuracy_score(y_test, anomalies, adjusted=False)
    f1_macro = f1_score(y_test, anomalies, average='macro')
    f1_micro = f1_score(y_test, anomalies, average='micro')

    result['gmean'] = gmean
    result['f1_macro'] = f1_macro
    result['f1_micro'] = f1_micro
    return result

# Pipeline
import keras_tuner as kt
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import IsolationForest

def train_model_with_model_return(model_name, x, y, x_test, y_test, train_dataset_name, scenario, epochs=25, feature_selection_method="SVM-RFE"):
    print(x_test.shape)
    print(x.shape)

    # Record the start time
    start_time = time.time()

    directory = model_name + str(x_test.shape[1])
    model = None  # Initialize model to None to avoid UnboundLocalError

    if model_name == "AE":
        print_green(f"Train AE model with {feature_selection_method}")
        monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)

        input_dim = x.shape[1]
        if feature_selection_method == "L1":
          model = AutoEncoderModel(input_dim, reg_type="L1", reg_strength=0.0001).build()
        elif feature_selection_method == "L2":
          model = AutoEncoderModel(input_dim, reg_type="L2", reg_strength=0.0001).build()
        else:
          model = AutoEncoderModel(input_dim).build()

        model.fit(x, x, epochs=epochs, validation_split=0.2, callbacks=[monitor])
    elif model_name == "AE_HT":

      # Get input dimension
      input_dim = x.shape[1]
      # Define a hypermodel with input_dim as an argument
      def hypermodel_builder(hp):
        # Select regularization based on feature selection method if desired
        reg_choice = None  # Default to no regularization
        if feature_selection_method == "L1":
            reg_choice = 'L1'
        elif feature_selection_method == "L2":
            reg_choice = 'L2'

        model = AutoEncoderHyperModel(input_dim, hp, reg_type=reg_choice).build()
        return model

      # Create a RandomSearch tuner (no changes needed here)
      tuner = kt.RandomSearch(
        hypermodel_builder,
        objective='val_loss',
        max_trials=10,
        directory='my_dir',
        project_name='autoencoder_tuning' + scenario + feature_selection_method
      )

      monitor = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)
      tuner.search(x, x, epochs=epochs, validation_split=0.2, callbacks=[monitor])

      # Get the optimal hyperparameters
      best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

      # Build the model with the best hyperparameters
      model = tuner.hypermodel.build(best_hps)
      model.fit(x, x, epochs=epochs, validation_split=0.2, callbacks=[monitor])
    elif model_name == "RF":
        model = RandomForestClassifier(n_estimators=100)  # You can adjust the number of trees with the `n_estimators` parameter
        model.fit(x, y)
    elif model_name == "RF_HT":
      # Define parameter grid
      param_grid = {
        'n_estimators': [100, 200, 300, 400, 500],
        'max_features': ['auto', 'sqrt', 'log2'],
        'max_depth': [4, 6, 8, 10, 12],
        'criterion': ['gini', 'entropy']
      }

      # Create a base model
      rf = RandomForestClassifier()

      # Instantiate GridSearchCV
      grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=2, n_jobs=-1, verbose=1)

      # Fit the grid search model
      grid_search.fit(x, y)

      # Best parameter set
      best_params = grid_search.best_params_

      # Best model
      model = grid_search.best_estimator_
    elif model_name == "XGBoost":
      model = XGBClassifier()
      model.fit(x, y)
    elif model_name == "XGBoost_HT":
      # Define parameter grid
      param_grid = {
          'n_estimators': [100, 200, 300],
          'learning_rate': [0.01, 0.1, 0.2, 0.3],
          'max_depth': [3, 4, 5],
          'min_child_weight': [1, 5, 10],
          'gamma': [0.5, 1, 1.5, 2],
          'subsample': [0.6, 0.8, 1.0],
          'colsample_bytree': [0.6, 0.8, 1.0]
        }

      # Create a base model
      xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

      # Instantiate GridSearchCV
      grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=2, n_jobs=-1, verbose=1)

      # Fit the grid search model
      grid_search.fit(x, y)

      # Best parameter set
      best_params = grid_search.best_params_

      # Best model
      model = grid_search.best_estimator_
    elif model_name == "CNN" or model_name == "CNN_HT":
        number_of_features = x.shape[1]
        print(f"Number of features in train: {number_of_features}")
        x_train_reshaped = x.reshape(x.shape[0], x.shape[1], 1)
        x_test_reshaped = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)
    
        monitor_val_loss = EarlyStopping(monitor='val_loss', patience=2)
        # Initialize the model
        model = Sequential()
    
        # Select the regularization type and strength
        if feature_selection_method == "L1":
            reg = l1(0.0001)
        elif feature_selection_method == "L2":
            reg = l2(0.0001)
        else:
            reg = None
    
        # Convolutional layers
        if x.shape[1] <= 3:
            kernel_size = 1
        else:
            kernel_size = 3
        model.add(Conv1D(filters=32, kernel_size=kernel_size, activation='relu', input_shape=(x_train_reshaped.shape[1:]), kernel_regularizer=reg))
        if x.shape[1] >= 2:
            model.add(MaxPooling1D(pool_size=2))
    
        # Flatten layer
        model.add(Flatten())
    
        # Fully connected layers with regularization
        model.add(Dense(64, activation='relu', kernel_regularizer=reg))
    
        # Output layer
        model.add(Dense(1, activation='sigmoid'))
    
        model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])
    
        model.summary()
    
        monitor_val_accuracy = EarlyStopping(monitor='val_accuracy', patience=2)
    
        model.fit(x_train_reshaped, y, validation_data=(x_test_reshaped, y_test), epochs=200, callbacks=[monitor_val_accuracy])
    elif model_name == "NN":
      print_green(f"Train NN model with {feature_selection_method}")
      class_weights = {0: 1. / len(y[y == 0]), 1: 1. / len(y[y == 1])}

      monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)

      input_dim = x.shape[1]
      if feature_selection_method == "L1":
        model = HCSModel(input_dim, reg_type="L1", reg_strength=1e-5).build()
      elif feature_selection_method == "L2":
        model = HCSModel(input_dim, reg_type="L2", reg_strength=1e-4).build()
      else:
        model = HCSModel(input_dim).build()
      model.fit(x, y, epochs=epochs, validation_split=0.2, callbacks=[monitor], class_weight=class_weights)
    elif model_name == "NN_HT":
        print_green(f"Train NN_HT model with {feature_selection_method}")
        input_dim = x.shape[1]

        def hypermodel_builder(hp):
            # Select regularization based on feature selection method if desired
            reg_choice = None  # Default to no regularization
            if feature_selection_method == "L1":
                reg_choice = 'L1'
            elif feature_selection_method == "L2":
                reg_choice = 'L2'

            model = HCSHyperModel(input_dim, hp, reg_type=reg_choice).build()
            return model

        # Create a RandomSearch tuner
        tuner = kt.RandomSearch(
            hypermodel_builder,
            objective='val_loss',
            max_trials=10,
            directory='my_dir',
            project_name='nn_tuning' + scenario + feature_selection_method
        )

        monitor = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)
        tuner.search(x, y, epochs=epochs, validation_split=0.2, callbacks=[monitor])

        # Get the optimal hyperparameters
        best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

        # Build the model with the best hyperparameters
        model = tuner.hypermodel.build(best_hps)
        class_weights = {0: 1. / len(y[y == 0]), 1: 1. / len(y[y == 1])}
        model.fit(x, y, epochs=epochs, validation_split=0.2, callbacks=[monitor], class_weight=class_weights)
    elif model_name == "IF":
      # Adjust these parameters based on experimentation
      n_estimators = 100  # Increased from 50
      contamination = 0.1  # Adjusted based on domain knowledge or data exploration
      max_features = 1
      # Assuming `x` does not need a target variable as IsolationForest is unsupervised
      model = IsolationForest(n_estimators=n_estimators, max_samples='auto', contamination=float(contamination), max_features=max_features)
      model.fit(x)  # Note: IsolationForest does not use `y` during fitting as it's unsupervised
    elif model_name == "IF_HT":
        
        # Define parameter grid
        param_grid_if = {
        'n_estimators': [50, 100, 150, 200, 250],
        'max_samples': ['auto', 0.5, 0.75],
        'contamination': [0.001, 0.01, 0.05, 0.1],
        'max_features': [0.5, 1.0],
        'bootstrap': [True, False]
        }

        # Create a base model
        model_if = IsolationForest()

        # Instantiate GridSearchCV
        grid_search = GridSearchCV(
            estimator=model_if,
            param_grid=param_grid_if,
            scoring=make_scorer(custom_f1_scorer),
            cv=2,
            n_jobs=-1,
            verbose=2)

        # Fit the grid search model
        grid_search.fit(x, y)  # Assuming you have a dataset X and true labels y

        # Best parameter set
        best_params = grid_search.best_params_

        # Best model
        model = grid_search.best_estimator_

    ensure_model_directory_exists(train_dataset_name)

    if model is None:
        return None

    anomalies = compute_model_predictions(model, model_name, x, y, x_test, y_test)
    results = evaluate_model(anomalies, y_test)
    auc_score = roc_auc_score(y_test, anomalies)  # Compute AUC score
    print_green(f"Model AUC score: {auc_score}")  # Print AUC score

    # Record the end time
    end_time = time.time()
    keras_tuner_total_time = end_time - start_time
    summary_plot_path, force_plot_path, force_plot_html_path = compute_shap_values_and_plots(model, x, model_name, f'plots/shap_plots/{scenario}_{feature_selection_method}_{train_dataset_name}')
    
    print(f"SHAP Summary Plot saved at: {summary_plot_path}")
    print(f"SHAP Force Plot saved at: {force_plot_path}")
    print(f"SHAP Force Plot HTML saved at: {force_plot_html_path}")

    return results, auc_score, x.shape[1], x.shape[1], keras_tuner_total_time, model

import shap

def compute_shap_values_and_plots(model, x, model_name, output_dir='plots/shap_plots/'):
    """
    Compute SHAP values and generate summary and force plots for different models.

    Parameters:
    - model: Trained machine learning model
    - x: Feature matrix used for training the model
    - model_name: Name of the model type (NN, AE, CNN, IF, XGBoost)
    - output_dir: Directory to save the SHAP plots
    """
    if model_name in ["NN", "AE", "CNN"]:
        # Ensure the input data is correctly shaped for SHAP DeepExplainer
        background = x[np.random.choice(x.shape[0], 100, replace=False)]  # Sample 100 instances for background data
        
        # Reshape background data if necessary to match the model input
        if len(background.shape) == 2:
            background = background.reshape((background.shape[0], background.shape[1], 1))

        explainer = shap.DeepExplainer(model, background)
        shap_values = explainer.shap_values(x)
    elif model_name in ["IF", "XGBoost"]:
        # Using a subset of background data for SHAP
        background_data = shap.sample(x, 100)  # Adjust the number of samples as needed
    
        # Create the explainer with the subset of background data
        explainer = shap.KernelExplainer(model.predict, background_data)
        
        # Measure time for a small subset to estimate full computation time
        small_subset_size = 100  # Adjust this size as needed for profiling
        small_subset = x[:small_subset_size]
        
        start_time = time.time()
        shap_values_subset = explainer.shap_values(small_subset)
        end_time = time.time()
        
        elapsed_time = end_time - start_time
        print(f"Time taken for {small_subset_size} samples: {elapsed_time} seconds")
        
        # Estimate time for the full dataset
        estimated_time = (len(x) / small_subset_size) * elapsed_time
        print(f"Estimated time for full dataset: {estimated_time} seconds")
        
        # Compute SHAP values for the full dataset
        shap_values = explainer.shap_values(x)
    else:
        raise ValueError(f"Unsupported model name: {model_name}")

    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Plot SHAP summary plot
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, x, plot_type="bar", show=False)
    summary_plot_path = os.path.join(output_dir, f'shap_summary_plot_{model_name}.png')
    plt.savefig(summary_plot_path)
    plt.close()

    # Adjust handling for force plot based on the model type
    if model_name in ["NN", "AE", "CNN"]:
        expected_value = explainer.expected_value[0]
        shap_values_instance = shap_values[0][0]
    else:
        expected_value = explainer.expected_value
        shap_values_instance = shap_values[0]
    
    # Plot SHAP force plot for the first instance
    plt.figure(figsize=(10, 6))
    shap.force_plot(expected_value, shap_values_instance, x[0], matplotlib=True)
    force_plot_path = os.path.join(output_dir, f'shap_force_plot_instance_{model_name}.png')
    plt.savefig(force_plot_path)
    plt.close()
    
    # Optional: Create a detailed force plot for an interactive view
    force_plot_html_path = os.path.join(output_dir, f'shap_force_plot_instance_{model_name}.html')
    shap.save_html(force_plot_html_path, shap.force_plot(expected_value, shap_values_instance, x[0]))

    print(f"SHAP plots for {model_name} saved successfully.")
    return summary_plot_path, force_plot_path, force_plot_html_path


def train_model(model_name, x, y, x_test, y_test, train_dataset_name, scenario, epochs=25, feature_selection_method="SVM-RFE"):
    results, auc_score, x_shape_1, x_shape_1, keras_tuner_total_time, model = train_model_with_model_return(model_name, x, y, x_test, y_test, train_dataset_name, scenario, epochs, feature_selection_method)
#    clean_up_model(model, model_name, train_dataset_name)

    return results, auc_score, x_shape_1, x_shape_1, keras_tuner_total_time

"""# Feature Selections

## Trank
"""

from sklearn.metrics import roc_auc_score

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

import time

from sklearn.feature_selection import SelectKBest, f_classif

def apply_trank(x_train, y_train, x_test, percent_of_features=0.5):
    print_green("Applying Trank feature selection...")

    # Calculate t-test scores for each feature
    f_scores, p_values = f_classif(x_train, y_train)
    f_scores[np.isnan(f_scores)] = 0
    p_values[np.isnan(p_values)] = 1

    # Calculate correlations with the target
    correlations = np.abs(np.array([np.corrcoef(x_train[:, i], y_train)[0, 1] if np.std(x_train[:, i]) > 0 else 0 for i in range(x_train.shape[1])]))
    correlations[np.isnan(correlations)] = 0

    # Combine scores and correlations into a single metric
    combined_metric = f_scores * correlations

    # Determine the number of features to select based on the specified percentage
    total_features = x_train.shape[1]
    top_n_features = int(total_features * percent_of_features)
    top_n_features = max(1, min(top_n_features, total_features))  # Ensure at least one feature is selected

    top_features_indices = np.argsort(combined_metric)[-top_n_features:]

    # Transform the datasets using the selected features
    x_train_selected = x_train[:, top_features_indices]
    x_test_selected = x_test[:, top_features_indices]

    # Log the scores, p-values, and correlation for each feature
    print_green("Feature ranking (t-test scores, p-values, correlation, combined metric):")
    for i in range(x_train.shape[1]):
        print(f"Feature {i}: Score = {f_scores[i]}, P-value = {p_values[i]}, Correlation = {correlations[i]}, Combined Metric = {combined_metric[i]}")

    print_green("All Features Scores and Rankings:")
    for i, (score, is_selected) in enumerate(zip(f_scores, top_features_indices)):
        print(f"Feature {i}: Score = {score}, Selected = {is_selected}")

    return x_train_selected, x_test_selected, top_features_indices

"""## Boruta"""

from boruta import BorutaPy
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import pandas as pd

def apply_boruta_feature_selection(x_train, y_train, x_test, estimator=None, max_iter=100, random_state=42):
    """
    Applies Boruta feature selection to identify important features.

    Parameters:
    - x_train: Training data features (Pandas DataFrame or Numpy array).
    - y_train: Training data target (Pandas Series or Numpy array).
    - x_test: Test data features (Pandas DataFrame or Numpy array).
    - estimator: The base estimator to use for Boruta. If None, RandomForestRegressor is used.
    - max_iter: Maximum number of iterations for Boruta.
    - random_state: Random state for reproducibility.

    Returns:
    - x_train_selected: Training data with only the selected features.
    - x_test_selected: Test data with only the selected features.
    - selected_features_indices: Indices of features selected by Boruta.
    """

    if estimator is None:
        estimator = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=random_state)

    # Ensure X and y are numpy arrays
    x_train_np = np.array(x_train)
    y_train_np = np.array(y_train)

    # Initialize Boruta
    feat_selector = BorutaPy(estimator, n_estimators='auto', max_iter=max_iter, random_state=random_state, verbose=2)

    # Fit Boruta
    feat_selector.fit(x_train_np, y_train_np)

    # Select features
    selected_features = feat_selector.support_
    selected_features_indices = np.where(selected_features)[0]

    # Transform X to include only selected features
    x_train_selected = feat_selector.transform(x_train_np)
    x_test_selected = feat_selector.transform(np.array(x_test))

    # If x_train was a DataFrame, convert the result back into DataFrame
    if isinstance(x_train, pd.DataFrame):
        selected_feature_names = x_train.columns[selected_features]
        x_train_selected = pd.DataFrame(x_train_selected, columns=selected_feature_names)
        x_test_selected = pd.DataFrame(x_test_selected, columns=selected_feature_names)

    return x_train_selected, x_test_selected, selected_features_indices

"""## ZScore"""

from scipy.stats import zscore

import numpy as np
from scipy.stats import zscore

def apply_zscore(x_train, x_test, percentile=85):
    """
    Apply Z-score based feature selection.

    Parameters:
    - x_train: Training data.
    - x_test: Test data.
    - percentile: The percentile to use as a threshold for feature selection.

    Returns:
    - x_train_selected: Training data with selected features.
    - x_test_selected: Test data with selected features.
    """
    # Calculate Z-scores of the training data
    z_scores = np.abs(zscore(x_train))

    # Determine the threshold based on the desired percentile
    threshold = np.percentile(z_scores, percentile)

    # Select features that have a Z-score less than the threshold
    selected_features = np.where((z_scores < threshold).all(axis=0))[0]

    # Check if any features are selected
    if len(selected_features) == 0:
        raise ValueError("No features selected. Consider using a higher percentile for feature selection.")

    x_train_selected = x_train[:, selected_features]
    x_test_selected = x_test[:, selected_features]

    print(f"Selected {len(selected_features)} features using Z-score with {percentile}th percentile as threshold.")

    return x_train_selected, x_test_selected

"""## LDA"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

def apply_lda_feature_selection(x_train, y_train, x_test, n_components=None):
    """
    Apply LDA for feature selection.

    Parameters:
    - x_train: Training data.
    - y_train: Training labels.
    - x_test: Test data.
    - n_components: Number of components (features) to keep.

    Returns:
    - x_train_lda: Transformed training data.
    - x_test_lda: Transformed test data.
    - lda: The LDA model.
    """

    # Set default n_components if not specified
    if n_components is None:
        n_classes = len(np.unique(y_train))
        n_features = x_train.shape[1]
        n_components = min(n_classes - 1, n_features)

    # Create an LDA object
    lda = LDA(n_components=n_components)

    # Fit the LDA model on the training data and transform both train and test sets
    x_train_lda = lda.fit_transform(x_train, y_train)
    x_test_lda = lda.transform(x_test)

    return x_train_lda, x_test_lda, lda

"""## Gain Ratio"""

from sklearn.feature_selection import mutual_info_classif

def apply_gain_ratio(x_train, y_train, x_test):
    # Compute mutual information for each feature
    mutual_info = mutual_info_classif(x_train, y_train)
    total_info = np.sum(mutual_info)
    # Compute gain ratio
    gain_ratios = mutual_info / total_info
    # Select features based on a threshold (e.g., median gain ratio)
    threshold = np.median(gain_ratios)
    selected_features = np.where(gain_ratios > threshold)[0]
    return x_train[:, selected_features], x_test[:, selected_features]

"""## SVM-RFE"""

from sklearn.feature_selection import RFE
from sklearn.svm import SVC

from sklearn.feature_selection import RFE
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

def apply_svm_rfe(x_train, y_train, x_test):
    print("Applying SVM-RFE feature selection...")

    # Create an SVM classifier
    svc = SVC(kernel="linear")

    # Create the RFE model
    rfe = RFE(estimator=svc, verbose=1)
    rfe.fit(x_train, y_train)

    # Log the ranking of the features
    print("Feature ranking (SVM-RFE):")
    for i, rank in enumerate(rfe.ranking_):
        print(f"Feature {i}: Rank = {rank}")

    # Select features with rank 1 or 2
    selected_features = [i for i, rank in enumerate(rfe.ranking_) if rank == 1 or rank == 2]

    # Transform the datasets using the selected features
    x_train_selected = x_train[:, selected_features]
    x_test_selected = x_test[:, selected_features]

    print("All Features Ranking (SVM-RFE):")
    for i, rank in enumerate(rfe.ranking_):
        is_selected = rank == 1 or rank == 2
        print(f"Feature {i}: Rank = {rank}, Selected = {is_selected}")

    selected_features_indices = np.where(rfe.ranking_ <= 2)[0]
    return x_train_selected, x_test_selected, selected_features_indices

"""## PCA"""

from sklearn.ensemble import RandomForestClassifier

from sklearn.decomposition import PCA

def apply_pca_reduction(x_train, x_test, n_components=None, explained_variance=None):
    """
    Apply PCA to the training and test data.

    Parameters:
    - x_train: Training data.
    - x_test: Test data.
    - n_components: Number of PCA components to keep.
    - explained_variance: Desired explained variance (if n_components is None).

    Returns:
    - x_train_pca: Transformed training data.
    - x_test_pca: Transformed test data.
    - pca: The PCA model.
    - selected_features: Indices of the original features that correspond to the selected PCA components.
    """
    if n_components is not None:
        pca = PCA(n_components=n_components)
    elif explained_variance is not None:
        pca = PCA(n_components=explained_variance)
    else:
        # Default to 95% explained variance if neither parameter is provided
        pca = PCA(n_components=0.95)

    x_train_pca = pca.fit_transform(x_train)
    x_test_pca = pca.transform(x_test)

    print(f"Cumulative explained variance by {pca.n_components_} components: {np.sum(pca.explained_variance_ratio_):.2f}")

    # Get the indices of the features that are the most important to the principal components
    most_important_features = np.argsort(np.abs(pca.components_), axis=1)[:, -1]

    return x_train_pca, x_test_pca, pca, most_important_features

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier
import numpy as np
from sklearn.feature_selection import SelectFromModel

def apply_rf_feature_importance(x_train, y_train, x_test):
    print("Applying Random Forest feature importance...")
    n_features = x_train.shape[1]

    # Optionally tune parameters of RandomForestClassifier for better performance
    rf = RandomForestClassifier(n_estimators=1000, max_features=n_features)
    rf.fit(x_train, y_train)

    sel = SelectFromModel(RandomForestClassifier(n_estimators = 1000, max_features=x_train.shape[1]))
    sel.fit(x_train, y_train)

    # # Log the importances of each feature

    # # Get feature importances
    # importances = rf.feature_importances_

    # # Calculate average importance
    # avg_importance = np.mean(importances)

    # # Select features with importance greater than average
    # selected_features = np.where(importances > avg_importance)[0]
    selected_features = np.where(sel.get_support())[0]

#    print(f"{selected_features}")
#    if isinstance(selected_features[0], int):
    # If selected_features contains integer positions, use iloc
    x_train_selected = x_train[:, selected_features]
    x_test_selected = x_test[:, selected_features]

    print(f"Selected features: {selected_features}")

    # print("All Features Importance and Selection Status:")
    # for i, importance in enumerate(importances):
    #     is_selected = i in selected_features
    #     print(f"Feature {i}: Importance = {importance}, Selected = {is_selected}")

    return x_train_selected, x_test_selected, selected_features

"""## MI"""

from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import RFE, SelectKBest, chi2
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.svm import SVC

def apply_mi(x_train, y_train, x_test):
    print_green("Applying Mutual Information feature selection...")

    # Check the number of unique labels
    unique_labels = np.unique(y_train)
    print_green(f"Number of unique labels: {len(unique_labels)}")

    # Calculate MI scores for each feature
    mi_scores = mutual_info_classif(x_train, y_train) + 1e-10  # Add a small constant for numeric stability
    mi_scores[np.isnan(mi_scores)] = 0

    # Calculate the average MI score
    avg_mi_score = np.mean(mi_scores)

    # Log the scores for each feature
    print_green("Feature ranking (MI scores):")
    for i, score in enumerate(mi_scores):
        print(f"Feature {i}: Score = {score}")

    # If all scores are essentially zero, keep all features
    if np.all(mi_scores <= 1e-10):
        print_green("All MI scores are approximately zero. Keeping all features.")
        return x_train, x_test

    # Create a mask for features with MI scores greater than the average
    selected_features = mi_scores > avg_mi_score

    # Transform the datasets using the selected features
    x_train_selected = x_train[:, selected_features]
    x_test_selected = x_test[:, selected_features]

    selected_features_indices = np.where(selected_features)[0]
    print_green("All Features MI Scores and Selection Status:")
    for i, score in enumerate(mi_scores):
        is_selected = selected_features[i]
        print(f"Feature {i}: Score = {score}, Selected = {is_selected}")
    return x_train_selected, x_test_selected, selected_features_indices

"""## LRS"""

def apply_lrs(x_train, y_train, x_test, estimator = RandomForestClassifier(n_estimators=100), L=2, R=1):
    print_green("Applying LRS feature selection...")

    # Initially, no features are selected
    selected_features = []

    while len(selected_features) < x_train.shape[1]:
        remaining_features = list(set(range(x_train.shape[1])) - set(selected_features))

        # Rank remaining features
        estimator.fit(x_train[:, remaining_features], y_train)
        if hasattr(estimator, 'feature_importances_'):
            feature_ranks = estimator.feature_importances_
        elif hasattr(estimator, 'coef_'):
            feature_ranks = np.abs(estimator.coef_[0])
        else:
            raise ValueError("Estimator must have feature_importances_ or coef_ attribute.")

        # Add L best features
        best_features = np.argsort(feature_ranks)[-L:]
        selected_features.extend([remaining_features[i] for i in best_features])

        # Remove R worst features
        if len(selected_features) > R:
            estimator.fit(x_train[:, selected_features], y_train)
            if hasattr(estimator, 'feature_importances_'):
                feature_ranks_selected = estimator.feature_importances_
            elif hasattr(estimator, 'coef_'):
                feature_ranks_selected = np.abs(estimator.coef_[0])

            worst_features = np.argsort(feature_ranks_selected)[:R]
            selected_features = [selected_features[i] for i in range(len(selected_features)) if i not in worst_features]

    x_train_selected = x_train[:, selected_features]
    x_test_selected = x_test[:, selected_features]

    return x_train_selected, x_test_selected, selected_features

"""## SFS"""

def apply_sfs(x_train, y_train, x_test):
    print_green("Applying SFS feature selection...")
    estimator = SVC(kernel="linear")
    sfs = SFS(estimator,
              k_features=(1, x_train.shape[1]),
              forward=True,
              floating=False,
              scoring='accuracy',
              cv=5)
    sfs = sfs.fit(x_train, y_train)
    x_train_selected = sfs.transform(x_train)
    x_test_selected = sfs.transform(x_test)

    selected_features_indices = list(sfs.k_feature_idx_)
    return x_train_selected, x_test_selected, selected_features_indices

"""## SBS"""

def apply_sbs(x_train, y_train, x_test):
    print_green("Applying SBS feature selection...")
    estimator = SVC(kernel="linear")
    sbs = SFS(estimator,
              k_features=1,
              forward=False,
              floating=False,
              scoring='accuracy',
              cv=5)
    sbs = sbs.fit(x_train, y_train)
    x_train_selected = sbs.transform(x_train)
    x_test_selected = sbs.transform(x_test)

    selected_features_indices = list(sbs.k_feature_idx_)
    return x_train_selected, x_test_selected, selected_features_indices

"""## SelectKBest"""

from sklearn.feature_selection import SelectKBest, mutual_info_classif
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier  # Example classifier
import numpy as np

def apply_selectkbest_f_classif(x_train, y_train, x_test, score_func=mutual_info_classif, cv=5): # binary_search
    max_k = x_train.shape[1]
    print("Starting binary search to find the best k...")

    classifier = RandomForestClassifier()
    best_score = 0
    best_k = 0
    low = 1
    high = max_k

    while low <= high:
        k = (low + high) // 2
        selector = SelectKBest(score_func, k=k)
        pipeline = make_pipeline(selector, classifier)
        scores = cross_val_score(pipeline, x_train, y_train, cv=cv)
        mean_score = np.mean(scores)
        print(f"k={k}: Cross-validated score = {mean_score}")

        if mean_score > best_score:
            best_score = mean_score
            best_k = k
            low = k + 1  # Search in the upper half
        else:
            high = k - 1  # Search in the lower half
    
    print(f"Best k: {best_k} with a score of {best_score}")

    selector = SelectKBest(score_func, k=best_k)
    x_train_selected = selector.fit_transform(x_train, y_train)
    x_test_selected = selector.transform(x_test)
    selected_features_indices = selector.get_support(indices=True)

    return x_train_selected, x_test_selected, selected_features_indices


"""## relief"""

from skrebate import ReliefF

# def apply_relief(x_train, y_train, x_test, m=100):
#     print_green("Applying Relief feature selection...")

#     # Number of features
#     n_features = x_train.shape[1]
#     scores = np.zeros(n_features)

#     # Compute for 'm' instances
#     for i in range(m):
#         idx = np.random.randint(x_train.shape[0])
#         instance, label = x_train[idx], y_train[idx]

#         # Find nearest hit and nearest miss
#         hit_mask = (y_train == label)
#         miss_mask = (y_train != label)

#         nn_hit = NearestNeighbors(n_neighbors=2).fit(x_train[hit_mask])
#         distance_hit, _ = nn_hit.kneighbors(instance.reshape(1, -1))

#         nn_miss = NearestNeighbors(n_neighbors=1).fit(x_train[miss_mask])
#         distance_miss, _ = nn_miss.kneighbors(instance.reshape(1, -1))

#         scores += distance_miss[0] - distance_hit[0][1]

#     # Keep top half features with highest scores
#     selected_indices = scores.argsort()[-(n_features//2):]
#     x_train_selected = x_train[:, selected_indices]
#     x_test_selected = x_test[:, selected_indices]

#     return x_train_selected, x_test_selected

def apply_relief(x_train, y_train, x_test, n_features_to_select=10):
    print_green("Applying Relief feature selection...")

    # Initialize Relief algorithm
    relief = ReliefF(n_features_to_select=n_features_to_select)

    # Fit and transform datasets
    relief.fit(x_train, y_train)
    x_train_selected = relief.transform(x_train)
    x_test_selected = relief.transform(x_test)

    return x_train_selected, x_test_selected

"""## CHi2"""

import numpy as np
from sklearn.feature_selection import SelectKBest, chi2

def apply_chi2(x_train, y_train, x_test):
    print("Applying Chi-Square feature selection...")

    # Fit to get chi-square values
    chi2_values = chi2(x_train, y_train)
    chi2_scores = chi2_values[0]  # Get the scores (chi2 statistics)

    chi2_scores[np.isnan(chi2_scores)] = 0

    # Calculate the average chi-square score
    avg_chi2_score = np.mean(chi2_scores)

    # Determine features with chi-square score greater than average
    selected_features_bool = chi2_scores > avg_chi2_score

    print("All Features Chi-Square Scores and Selection Status:")
    for i, score in enumerate(chi2_scores):
        is_selected = selected_features_bool[i]
        print(f"Feature {i}: Score = {score}, Selected = {is_selected}")

    # Select features based on the boolean mask
    x_train_selected = x_train[:, selected_features_bool]
    x_test_selected = x_test[:, selected_features_bool]

    selected_features_indices = np.where(selected_features_bool)[0]

    return x_train_selected, x_test_selected, selected_features_indices

"""## PSO"""

import numpy as np
import pandas as pd
from random import uniform, randrange, random
from sklearn.metrics import accuracy_score
from random import random as r # This import statement is important
from sklearn.linear_model import LogisticRegression

# Define the Particle class from your PSO implementation
class Particle:
    def __init__(self, x0):
        self.position_i = []  # particle position
        self.velocity_i = []  # particle velocity
        self.pos_best_i = []  # best position individual
        self.f1_best_i = -1  # best error individual
        self.f1_i = -1  # error individual

        for i in range(num_dimensions):
            self.velocity_i.append(uniform(-1, 1))
            self.position_i.append(x0[i])

    # evaluate current fitness
    def evaluate(self, costFunc):
        self.f1_i = costFunc(self.position_i)

        # check to see if the current position is an individual best
        if self.f1_i > self.f1_best_i or self.f1_best_i == -1:
            self.pos_best_i = self.position_i
            self.f1_best_i = self.f1_i

    # update new particle velocity
    def update_velocity(self, pos_best_global):
        w = 0.5  # constant inertia weight
        c1 = 1   # cognitive constant
        c2 = 2   # social constant

        for i in range(0, num_dimensions):
            r1 = r()  # Use random() function from the random module
            r2 = r()

            vel_cognitive = c1 * r1 * (self.pos_best_i[i] - self.position_i[i])
            vel_social = c2 * r2 * (pos_best_global[i] - self.position_i[i])
            self.velocity_i[i] = w * self.velocity_i[i] + vel_cognitive + vel_social

    # update the particle position based off new velocity updates
    def update_position(self, bounds):
        for i in range(0, num_dimensions):
            self.position_i[i] = self.position_i[i] + self.velocity_i[i]

            # adjust maximum position if necessary
            if self.position_i[i] > bounds[i][1]:
                self.position_i[i] = bounds[i][1]

            # adjust minimum position if neseccary
            if self.position_i[i] < bounds[i][0]:
                self.position_i[i] = bounds[i][0]

# Function to optimize using PSO
def apply_custom_pso(x_train, y_train, x_test, y_test, estimator, pso_options):
    global num_dimensions, pos_best_global

    num_dimensions = x_train.shape[1]  # Number of features/dimensions
    pos_best_global = []  # best position for group
    f1_best_global = -1  # best error for group
    bounds = [(0, 1) for _ in range(num_dimensions)]  # Bounds for features

    def objective_function(solution):
        solution_array = np.array(solution)  # Convert to NumPy array for element-wise comparison
        selected_features = np.where(solution_array > 0.5)[0]
        if len(selected_features) == 0:
            return 0  # No features selected, return worst score

        x_train_selected = x_train[:, selected_features]
        x_test_selected = x_test[:, selected_features]

        estimator.fit(x_train_selected, y_train)
        predictions = estimator.predict(x_test_selected)
        score = accuracy_score(y_test, predictions)
        return score

    swarm = [Particle([uniform(bounds[i][0], bounds[i][1]) for i in range(num_dimensions)]) for _ in range(pso_options['n_particles'])]

    for i in range(pso_options['iters']):
        # Evaluate fitness
        for j in range(pso_options['n_particles']):
            swarm[j].evaluate(objective_function)

            # Determine if current particle is the best (globally)
            if swarm[j].f1_i > f1_best_global or f1_best_global == -1:
                pos_best_global = list(swarm[j].position_i)
                f1_best_global = float(swarm[j].f1_i)

        # Update velocity and position
        for j in range(pso_options['n_particles']):
            swarm[j].update_velocity(pos_best_global)
            swarm[j].update_position(bounds)

    # After the loop, use the global best position to select features
    best_solution_array = np.array(pos_best_global)  # Convert to a NumPy array
    best_solution = np.where(best_solution_array > 0.5)[0]
    x_train_selected = x_train[:, best_solution]
    x_test_selected = x_test[:, best_solution]

    return x_train_selected, x_test_selected, best_solution

"""## Balance & Apply FS"""

def apply_feature_selection(x_train, y_train, x_test, y_test, method="SVM-RFE"):
    start_time = time.time()  # Start time for feature selection

    original_features = x_train.shape[1]
    print_green(f"Number of features before feature selection: {original_features}")

    # Initialize with all indices
    selected_features_indices = list(range(original_features))

    if method == "trank":
        x_train_selected, x_test_selected, selected_features_indices = apply_trank(x_train, y_train, x_test)
    elif method == "PSO":
      estimator = LogisticRegression()
      pso_options = {
      'n_particles': 15,
      'bounds': [(0.1, 0.4), (50, 1000)],
      'iters': 100
      }
      x_train_selected, x_test_selected, selected_features_indices = apply_custom_pso(x_train, y_train, x_test, y_test, estimator, pso_options)
    elif method == "SVM-RFE":
        x_train_selected, x_test_selected, selected_features_indices = apply_svm_rfe(x_train, y_train, x_test)
    elif method == "RF":
        x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train, y_train, x_test)
    elif method == "MI":
        x_train_selected, x_test_selected, selected_features_indices = apply_mi(x_train, y_train, x_test)
    elif method == "LRS":
        x_train_selected, x_test_selected, selected_features_indices = apply_lrs(x_train, y_train, x_test)
    elif method == "SFS":
        x_train_selected, x_test_selected, selected_features_indices = apply_sfs(x_train, y_train, x_test)
    elif method == "SBS":
        x_train_selected, x_test_selected, selected_features_indices = apply_sbs(x_train, y_train, x_test)
    elif method == "Zscore":
        x_train_selected, x_test_selected = apply_zscore(x_train, x_test)
    elif method == "Gain Ratio":
        x_train_selected, x_test_selected = apply_gain_ratio(x_train, y_train, x_test)
    elif method == "LDA":
        x_train_selected, x_test_selected, _ = apply_lda_feature_selection(x_train, y_train, x_test)
    elif method == "SelectKBest":
        x_train_selected, x_test_selected, selected_features_indices = apply_selectkbest_f_classif(x_train, y_train, x_test)
    elif method == "Relief":
        x_train_selected, x_test_selected, selected_features_indices = apply_relief(x_train, y_train, x_test)
    elif method == "Chi2":
        x_train_selected, x_test_selected, selected_features_indices = apply_chi2(x_train, y_train, x_test)
    elif method == "Boruta":
        x_train_selected, x_test_selected, selected_features_indices = apply_boruta_feature_selection(x_train, y_train, x_test)
    elif method == "RA": # Trank RF
        label_1_count = np.count_nonzero(y_train)
        label_0_count = len(y_train) - label_1_count
        if label_1_count / label_0_count < 1:
            print_green(f"Applying {method} feature selection")
            print_green(f"Total Features: {x_train.shape[1]}")
            x_train_selected, x_test_selected, selected_features_indices = apply_trank(x_train, y_train, x_test)
            print_green(f"{selected_features_indices} features selected by Atena Phase I")
            x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train_selected, y_train, x_test_selected)
            print_green(f"{selected_features_indices} features selected by Atena Phase II")
        else:
            print_green(f"Applying {method} feature selection")
            print_green(f"Total Features: {x_train.shape[1]}")
            x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train, y_train, x_test)
            print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Atena": # Trank RF
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_trank(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train_selected, y_train, x_test_selected)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Horus": # SKB RF
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_selectkbest_f_classif(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train_selected, y_train, x_test_selected)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Horus 3": # Trank PSO
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_trank(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        estimator = LogisticRegression()
        pso_options = {
            'n_particles': 15,
            'bounds': [(0.1, 0.4), (50, 1000)],
            'iters': 100}
        x_train_selected, x_test_selected, selected_features_indices = apply_custom_pso(x_train_selected, y_train, x_test_selected, y_test, estimator, pso_options)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Horus 4": # CHI2 PSO
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_chi2(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        estimator = LogisticRegression()
        pso_options = {
            'n_particles': 15,
            'bounds': [(0.1, 0.4), (50, 1000)],
            'iters': 100}
        x_train_selected, x_test_selected, selected_features_indices = apply_custom_pso(x_train_selected, y_train, x_test_selected, y_test, estimator, pso_options)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Horus 5": # SKB PSO
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_selectkbest_f_classif(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        estimator = LogisticRegression()
        pso_options = {
            'n_particles': 15,
            'bounds': [(0.1, 0.4), (50, 1000)],
            'iters': 100}
        x_train_selected, x_test_selected, selected_features_indices = apply_custom_pso(x_train_selected, y_train, x_test_selected, y_test, estimator, pso_options)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Horus 2": # MI PSO
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_mi(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        estimator = LogisticRegression()
        pso_options = {
            'n_particles': 15,
            'bounds': [(0.1, 0.4), (50, 1000)],
            'iters': 100}
        x_train_selected, x_test_selected, selected_features_indices = apply_custom_pso(x_train_selected, y_train, x_test_selected, y_test, estimator, pso_options)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Hades": # PCA PSO
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, _, selected_features_indices = apply_pca_reduction(x_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        estimator = LogisticRegression()
        pso_options = {
            'n_particles': 15,
            'bounds': [(0.1, 0.4), (50, 1000)],
            'iters': 100}
        x_train_selected, x_test_selected, selected_features_indices = apply_custom_pso(x_train_selected, y_train, x_test_selected, y_test, estimator, pso_options)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "PCA": # PCA 2
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, _, selected_features_indices = apply_pca_reduction(x_train, x_test)
    elif method == "Anobis": # Chi2 RF
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_chi2(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train_selected, y_train, x_test_selected)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Hera": # PCA RF
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, _, selected_features_indices = apply_pca_reduction(x_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train_selected, y_train, x_test_selected)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    elif method == "Persus": # MI RF
        print_green("Applying Atena feature selection")
        print_green(f"Total Features: {x_train.shape[1]}")
        x_train_selected, x_test_selected, selected_features_indices = apply_mi(x_train, y_train, x_test)
        print_green(f"{selected_features_indices} features selected by Atena Phase I")
        x_train_selected, x_test_selected, selected_features_indices = apply_rf_feature_importance(x_train_selected, y_train, x_test_selected)
        print_green(f"{selected_features_indices} features selected by Atena Phase II")
    else:
        x_train_selected, x_test_selected = x_train, x_test

    selected_features = x_train_selected.shape[1]
    print_green(f"Number of features after feature selection: {selected_features}")
    print_green(f"Selected Features for {method}")
    if selected_features_indices is not None:
      for i in selected_features_indices:
        print(f"Feature {i}")

    end_time = time.time()  # End time for feature selection
    elapsed_time = (end_time - start_time)
    print_green(f"Time taken for feature selection: {elapsed_time:.2f} seconds")

    return x_train_selected, x_test_selected, elapsed_time, selected_features_indices

def align_features(train, test):
    # Get missing columns in the test set
    missing_cols = set(train.columns) - set(test.columns)

    # Add a missing column in the test set with default value equal to 0
    for c in missing_cols:
        test[c] = 0

    # Ensure the order of the columns in the test set is the same as in the training set
    test = test[train.columns]

    return train, test
    
def balance_data_and_apply_feature_selection(x, x_test, y, y_test, scenario, feature_selection_method):
  original_features = x.shape[1]
  # Initialize with all indices
  selected_features_indices = list(range(original_features))
    
  if scenario in ["S2", "S7"]:

    # Initialize SMOTE
    smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

    # Fit and resample the data
    x, y = smote.fit_resample(x, y)

    return x, x_test, y, 0, selected_features_indices
  elif scenario in ["S3", "S8"]:

    # Initialize SMOTE
    smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

    # Fit and resample the data
    x, y = smote.fit_resample(x, y)

    if feature_selection_method == "None":
        return x, x_test, y, 0, selected_features_indices
    else:
        x_selected, x_test_selected, elapsed_time, selected_features_indices = apply_feature_selection(x, y, x_test, y_test, feature_selection_method)
        return x_selected, x_test_selected, y, elapsed_time, selected_features_indices

  elif scenario in ["S4", "S9"]:
    if feature_selection_method == "None":
      # Initialize SMOTE
      smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

      # Fit and resample the data
      x, y = smote.fit_resample(x, y)

      return x, x_test, y, 0, selected_features_indices
    else:
      x, x_test, elapsed_time, selected_features_indices = apply_feature_selection(x, y, x_test, y_test, feature_selection_method)

      # Initialize SMOTE
      smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

      # Fit and resample the data
      x, y = smote.fit_resample(x, y)

      return x, x_test, y, elapsed_time, selected_features_indices
  elif scenario == "S0" or scenario == "S5":
    return x, x_test, y, 0, selected_features_indices
  elif scenario == "S1" or scenario == "S6":
    if feature_selection_method == "None":
      return x, x_test, y, 0, selected_features_indices
    else:
      x_selected, x_test_selected, elapsed_time, selected_features_indices = apply_feature_selection(x, y, x_test, y_test, feature_selection_method)
      return x_selected, x_test_selected, y, elapsed_time, selected_features_indices

def balance_data_and_apply_feature_selection_bert(x, x_test, y, y_test, scenario, feature_selection_method, isCIC=False):
  original_features = x.shape[1]
  # Initialize with all indices
  selected_features_indices = list(range(original_features))
  
  print(x)

  if scenario in ["S0", "S1", "S5", "S6"]:
    x = preprocess_data_with_one_hot(x, isCIC)
    x_test = preprocess_data_with_one_hot(x_test, isCIC)
    x, x_test = align_features(x, x_test)
  else:
    # Initialize label encoder
    label_encoders = {}
    for column in x.columns:
        if x[column].dtype == 'object' or x[column].dtype == 'int':
            # Convert the column to string
            x[column] = x[column].astype(str)
            x_test[column] = x_test[column].astype(str)
            
            le = LabelEncoder()
            # Fit on the combined unique values of train and test sets
            le.fit(pd.concat([x[column], x_test[column]]).unique())
            x[column] = le.transform(x[column])
            # Use a placeholder value for unknown categories in the test set
            x_test[column] = le.transform(x_test[column].map(lambda s: s if s in le.classes_ else 'unknown'))
            label_encoders[column] = le
  
  print_green("Applying Data Scaling ....")
  scaler = MinMaxScaler(feature_range=(0, 1))
  x_scaled = scaler.fit_transform(x)
  x_test_scaled = scaler.transform(x_test)
  x_scaled_df = pd.DataFrame(x_scaled, columns=x.columns)
  x_test_scaled_df = pd.DataFrame(x_test_scaled, columns=x_test.columns)
  
  if scenario in ["S2", "S7"]:

    # Initialize SMOTE
    smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

    # Fit and resample the data
    x, y = smote.fit_resample(x, y)
    
    # Reverse label encoding
    for column, le in label_encoders.items():
        x[column] = le.inverse_transform(x[column])
        x_test[column] = le.inverse_transform(x_test[column])

    return x, x_test, y, 0, selected_features_indices
  elif scenario in ["S3", "S8"]:
    # After preprocessing (e.g., label encoding)
    print("Columns before label encoding:", x.columns.tolist())

    # Initialize SMOTE
    smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

    # Fit and resample the data
    x, y = smote.fit_resample(x, y)
    
    x_scaled = scaler.fit_transform(x)
    x_test_scaled = scaler.transform(x_test)
    
    # After preprocessing (e.g., label encoding)
    print("Columns after label encoding:", x.columns.tolist())

    x_selected, x_test_selected, elapsed_time, selected_features_indices = apply_feature_selection(x_scaled, y, x_test_scaled, y_test, feature_selection_method)
    
    # Reverse label encoding
    for column, le in label_encoders.items():
        x[column] = le.inverse_transform(x[column])
        x_test[column] = le.inverse_transform(x_test[column])
    return x, x_test, y, elapsed_time, selected_features_indices
  elif scenario in ["S4", "S9"]:
    x_selected, x_test_selected, elapsed_time, selected_features_indices = apply_feature_selection(x_scaled, y, x_test_scaled, y_test, feature_selection_method)

    # Initialize SMOTE
    smote = SMOTE(k_neighbors=5)  # Or whichever k you prefer

    # Fit and resample the data
    x, y = smote.fit_resample(x, y)
    
    # Reverse label encoding
    for column, le in label_encoders.items():
        x[column] = le.inverse_transform(x[column])
        x_test[column] = le.inverse_transform(x_test[column])

    return x, x_test, y, elapsed_time, selected_features_indices
  elif scenario == "S0" or scenario == "S5":
    return x, x_test, y, 0, selected_features_indices
  elif scenario == "S1" or scenario == "S6":
    if feature_selection_method == "None":
      return x, x_test, y, 0, selected_features_indices
    else:
      x_selected, x_test_selected, elapsed_time, selected_features_indices = apply_feature_selection(x_scaled, y, x_test_scaled, y_test, feature_selection_method)
      return x, x_test, y, elapsed_time, selected_features_indices
